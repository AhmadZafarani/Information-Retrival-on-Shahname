{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rocchio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class QueryExpansion:\n",
        "  def __init__(self, word_vectors, a1 , fasttext_vectors, weight_type = 'simple', dims=100):\n",
        "    self.fasttext_vectors = fasttext_vectors\n",
        "    self.weight_type = weight_type\n",
        "    self.docs = a1\n",
        "    self.dims = dims\n",
        "    self.word_vectors = word_vectors\n",
        "    self.vectorizer = TfidfVectorizer(use_idf = True, norm ='l1', ngram_range=(1,1), analyzer='word')\n",
        "    self.vectorizer.fit_transform(self.docs)\n",
        "    self.strings = []\n",
        "    string = ''\n",
        "    for item in self.vectorizer.get_feature_names():\n",
        "      string += item\n",
        "      string += ' '\n",
        "      self.strings.append(item)\n",
        "    self.vector = self.vectorizer.transform([string])\n",
        "    self.vector = self.vector.toarray()\n",
        "  \n",
        "  def get_fasttext_average_tf_idf_wights(self,mesra):\n",
        "    vector_sum = np.zeros(self.dims)\n",
        "    words = mesra.split(' ')\n",
        "    try:\n",
        "      for word in words:\n",
        "        index = self.strings.index(word)\n",
        "        vector_sum += self.word_vectors[word] * self.vector[0][index]\n",
        "    except Exception as e:\n",
        "      pass\n",
        "      # print(e.args[0])\n",
        "    return vector_sum\n",
        "  \n",
        "  def get_fastext_average(self,mesra):\n",
        "    counter = 0\n",
        "    vector_sum = np.zeros(self.dims)\n",
        "    words = mesra.split(' ')\n",
        "    for word in words:\n",
        "      try:\n",
        "        vector_sum += self.word_vectors[word]\n",
        "        counter += 1\n",
        "      except:\n",
        "        continue\n",
        "      vector_sum /= counter\n",
        "    return vector_sum\n",
        "\n",
        "  def get_fasttext(self, mesra):\n",
        "    if self.weight_type == 'tfidf':\n",
        "      return self.get_fasttext_average_tf_idf_wights(mesra)\n",
        "    elif self.weight_type == 'simple':\n",
        "      return self.get_fastext_average(mesra)\n",
        "\n",
        "  def query_expansion(self,query):\n",
        "    number_of_related_queries = 100\n",
        "    vector = self.get_fasttext(query)\n",
        "    vector /= np.linalg.norm(vector)\n",
        "    final_vector = np.matmul(self.fasttext_vectors, np.transpose(vector))\n",
        "    sen_v2 = np.copy(self.docs)\n",
        "    R = np.array(final_vector).argsort()[-number_of_related_queries:][::-1]\n",
        "    NR = np.array(final_vector).argsort()[:number_of_related_queries][::-1]\n",
        "    R_mean = np.mean(self.fasttext_vectors[R])\n",
        "    NR_mean = np.mean(self.fasttext_vectors[NR])\n",
        "    expanded_vector = vector + 1.5 * R_mean - 0.4 * NR_mean\n",
        "    expanded_vector /= np.linalg.norm(expanded_vector)\n",
        "    final_vector_expanded = np.matmul(self.fasttext_vectors, np.transpose(expanded_vector))\n",
        "    R_expanded = np.array(final_vector).argsort()[-1:][::-1]\n",
        "    expanded_query = sen_v2[R_expanded]\n",
        "    return expanded_query\n",
        "\n"
      ],
      "metadata": {
        "id": "B0H-CyM2SBIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell only once\n",
        "word_vectors = KeyedVectors.load_word2vec_format('vec_file.vec')\n",
        "with open('sen_v2.txt', 'r') as f:\n",
        "  sen_v2 = f.read()\n",
        "sen_v2 = sen_v2.split('\\n')\n",
        "sen_v2 = np.array(sen_v2)\n",
        "fasttext_vectors = np.loadtxt('fasttext_vectors.txt')\n",
        "nan_indexes = []\n",
        "for i in range(len(final_vector)):\n",
        "  if(np.isnan(fasttext_vectors[i]).any()):\n",
        "    nan_indexes.append(i)\n",
        "fasttext_vectors= np.delete(fasttext_vectors, nan_indexes, axis = 0)\n",
        "sen_v2= np.delete(sen_v2, nan_indexes, axis = 0)\n",
        "query_expander = QueryExpansion(word_vectors, sen_v2,  fasttext_vectors, 'simple' )"
      ],
      "metadata": {
        "id": "IXx26_7JjF_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query expansion\n",
        "query = 'کزین برتر اندیشه'\n",
        "query_expander.query_expansion(query)"
      ],
      "metadata": {
        "id": "RIGWIQmojNM3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}